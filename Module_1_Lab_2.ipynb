{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshaya34673/AIML/blob/main/Module_1_Lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLJihZwl-rvR"
      },
      "source": [
        "**Machine Learning terms and metrics & Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ec35lZf7-3v1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w12Iy5Vb-4QL",
        "outputId": "49dc26f1-2367-440c-9e4a-8b3f9e5f94b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            ":Number of Instances: 20640\n",
            "\n",
            ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            ":Attribute Information:\n",
            "    - MedInc        median income in block group\n",
            "    - HouseAge      median house age in block group\n",
            "    - AveRooms      average number of rooms per household\n",
            "    - AveBedrms     average number of bedrooms per household\n",
            "    - Population    block group population\n",
            "    - AveOccup      average number of household members\n",
            "    - Latitude      block group latitude\n",
            "    - Longitude     block group longitude\n",
            "\n",
            ":Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
            "\n",
            "The target variable is the median house value for California districts,\n",
            "expressed in hundreds of thousands of dollars ($100,000).\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "A household is a group of people residing within a home. Since the average\n",
            "number of rooms and bedrooms in this dataset are provided per household, these\n",
            "columns may take surprisingly large values for block groups with few households\n",
            "and many empty houses, such as vacation resorts.\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. rubric:: References\n",
            "\n",
            "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "  Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset = datasets.fetch_california_housing()\n",
        "# Dataset description\n",
        "print(dataset.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7T_Jh-P-6Wd",
        "outputId": "ccccbb00-028a-49fe-f2a7-72e2e602f033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orignal target values: [4.526 3.585 3.521 ... 0.923 0.847 0.894]\n",
            "Target values after conversion: [4 3 3 ... 0 0 0]\n",
            "Input variables shape: (20640, 8)\n",
            "Output variables shape: (20640,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Orignal target values:\", dataset.target)\n",
        "\n",
        "dataset.target = dataset.target.astype(int)\n",
        "\n",
        "print(\"Target values after conversion:\", dataset.target)\n",
        "print(\"Input variables shape:\", dataset.data.shape)\n",
        "print(\"Output variables shape:\", dataset.target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CChY28kD-_o1"
      },
      "outputs": [],
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "    diff = (\n",
        "        traindata - query\n",
        "    )\n",
        "    sq = diff * diff\n",
        "    dist = sq.sum(1)\n",
        "    label = trainlabel[np.argmin(dist)]\n",
        "    return label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lNKU1N8B_D-i"
      },
      "outputs": [],
      "source": [
        "def NN(traindata, trainlabel, testdata):\n",
        "    predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "    return predlabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tSUaPKfh_P2S"
      },
      "outputs": [],
      "source": [
        "def RandomClassifier(traindata, trainlabel, testdata):\n",
        "    classes = np.unique(trainlabel)\n",
        "    rints = rng.integers(low=0, high=len(classes), size=len(testdata))\n",
        "    predlabel = classes[rints]\n",
        "    return predlabel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LBdMKUri_VW5"
      },
      "outputs": [],
      "source": [
        "def Accuracy(gtlabel, predlabel):\n",
        "    assert len(gtlabel) == len(\n",
        "        predlabel\n",
        "    ),\"Length of the ground-truth labels and predicted labels should be the same\"\n",
        "    correct = (\n",
        "        gtlabel == predlabel\n",
        "    ).sum()\n",
        "    return correct / len(gtlabel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SBmq1uYU_cgI"
      },
      "outputs": [],
      "source": [
        "def split(data, label, percent):\n",
        "    rnd = rng.random(len(label))\n",
        "    split1 = rnd < percent\n",
        "    split2 = rnd >= percent\n",
        "\n",
        "    split1data = data[split1, :]\n",
        "    split1label = label[split1]\n",
        "    split2data = data[split2, :]\n",
        "    split2label = label[split2]\n",
        "    return split1data, split1label, split2data, split2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbV6izOI_kBH",
        "outputId": "99eda393-451d-4775-d3fe-87112c027c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test samples: 4144\n",
            "Number of train samples: 16496\n",
            "Percent of test data: 20.07751937984496 %\n"
          ]
        }
      ],
      "source": [
        "testdata, testlabel, alltraindata, alltrainlabel = split(\n",
        "    dataset.data, dataset.target, 20 / 100\n",
        ")\n",
        "print(\"Number of test samples:\", len(testlabel))\n",
        "print(\"Number of train samples:\", len(alltrainlabel))\n",
        "print(\"Percent of test data:\", len(testlabel) * 100 / len(dataset.target), \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89hR_V1o_r2z"
      },
      "source": [
        "# Experiments with splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lSLHy0Mv_nam"
      },
      "outputs": [],
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 75 / 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAVK-w2P_wDK",
        "outputId": "8f9a8e9d-0115-43a8-fef2-c9dc04a4e62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy using nearest neighbour algorithm: 100.0 %\n",
            "Training accuracy using random classifier:  16.4375808538163 %\n"
          ]
        }
      ],
      "source": [
        "trainpred = NN(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Training accuracy using nearest neighbour algorithm:\", trainAccuracy*100, \"%\")\n",
        "\n",
        "trainpred = RandomClassifier(traindata, trainlabel, traindata)\n",
        "trainAccuracy = Accuracy(trainlabel, trainpred)\n",
        "print(\"Training accuracy using random classifier: \", trainAccuracy*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsUcuIDB_yJD",
        "outputId": "057254a1-acb6-4171-9fef-f8ff45839bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 34.10852713178294 %\n",
            "Validation accuracy using random classifier: 16.884689922480618 %\n"
          ]
        }
      ],
      "source": [
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")\n",
        "\n",
        "\n",
        "valpred = RandomClassifier(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using random classifier:\", valAccuracy*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEdXTZYN_0Zs",
        "outputId": "14e43785-9610-44d3-b02f-d83a0d220da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy using nearest neighbour algorithm: 34.048257372654156 %\n"
          ]
        }
      ],
      "source": [
        "traindata, trainlabel, valdata, vallabel = split(\n",
        "    alltraindata, alltrainlabel, 75 / 100)\n",
        "valpred = NN(traindata, trainlabel, valdata)\n",
        "valAccuracy = Accuracy(vallabel, valpred)\n",
        "print(\"Validation accuracy using nearest neighbour algorithm:\", valAccuracy*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJnEvx8S_4Ij",
        "outputId": "954d1b5c-6888-4d00-870b-976c144bcb7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 34.91795366795367 %\n"
          ]
        }
      ],
      "source": [
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "testAccuracy = Accuracy(testlabel, testpred)\n",
        "\n",
        "print(\"Test accuracy:\", testAccuracy*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrhNDvpONdiW"
      },
      "source": [
        "# Multiple Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LU9gJ8AU_9ka"
      },
      "outputs": [],
      "source": [
        "def AverageAccuracy(alldata, alllabel, splitpercent, iterations, classifier=NN):\n",
        "    accuracy = 0\n",
        "    for ii in range(iterations):\n",
        "        traindata, trainlabel, valdata, vallabel = split(\n",
        "            alldata, alllabel, splitpercent\n",
        "        )\n",
        "        valpred = classifier(traindata, trainlabel, valdata)\n",
        "        accuracy += Accuracy(vallabel, valpred)\n",
        "    return accuracy / iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71vyqsEPNkf1",
        "outputId": "e50f5f8d-1879-4269-ad78-0ae2dadfc11a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average validation accuracy: 33.58463539517022 %\n",
            "Test accuracy: 34.91795366795367 %\n"
          ]
        }
      ],
      "source": [
        "avg_acc = AverageAccuracy(alltraindata, alltrainlabel, 75 / 100, 10, classifier=NN)\n",
        "print(\"Average validation accuracy:\", avg_acc*100, \"%\")\n",
        "testpred = NN(alltraindata, alltrainlabel, testdata)\n",
        "\n",
        "print(\"Test accuracy:\", Accuracy(testlabel, testpred)*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1R3gHH0Nwkq"
      },
      "source": [
        "# Section 2 - Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "M0eX2yMbNnN5"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from sklearn.utils.extmath import cartesian\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "\n",
        "rng = np.random.default_rng(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "N734ddjKN1Nm"
      },
      "outputs": [],
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "    diff = (\n",
        "        traindata - query\n",
        "    )\n",
        "    sq = diff * diff\n",
        "    dist = sq.sum(1)\n",
        "    label = trainlabel[np.argmin(dist)]\n",
        "    return label\n",
        "\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "    traindata = traindata.reshape(-1, 28*28)\n",
        "    testdata = testdata.reshape(-1, 28*28)\n",
        "    predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "    return predlabel\n",
        "\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "    assert len(gtlabel) == len(\n",
        "        predlabel\n",
        "    ), \"Length of the ground-truth labels and predicted labels should be the same\"\n",
        "    correct = (\n",
        "        gtlabel == predlabel\n",
        "    ).sum()\n",
        "    return correct / len(gtlabel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTM3R1oaODWO"
      },
      "outputs": [],
      "source": [
        "testpred = NN(train_X, train_y, test_X)\n",
        "print(\"Baseline accuracy without augmentation:\",\n",
        "      Accuracy(test_y, testpred)*100, \"%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91x-ZTg5Ou1e"
      },
      "source": [
        "# Augmentation 1: Rotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUCjaNa9Omnu"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(train_X[2], cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(rotate(train_X[2], 10), cmap=\"gray\")\n",
        "axs[1].set_title(\"Rotate +10 degrees\")\n",
        "\n",
        "axs[2].imshow(rotate(train_X[2], -10), cmap=\"gray\")\n",
        "axs[2].set_title(\"Rotate -10 degrees\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs77_VrUOGer"
      },
      "outputs": [],
      "source": [
        "def augRotate(sample, angleconstraint):\n",
        "    if angleconstraint == 0:\n",
        "        return sample\n",
        "    if len(sample.shape) == 2:\n",
        "\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    angle = rng.random(len(sample))\n",
        "\n",
        "    angle = (angle - 0.5) * angleconstraint\n",
        "    nsample = sample.copy()\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = rotate(sample[ii], angle[ii])\n",
        "    return np.squeeze(nsample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hu1_6NZO8YX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage import rotate\n",
        "def augRotate(sample, angleconstraint):\n",
        "    if angleconstraint == 0:\n",
        "        return sample\n",
        "    if len(sample.shape) == 2:\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    # Define rng as a random number generator from numpy\n",
        "    rng = np.random.default_rng()\n",
        "    angle = rng.random(len(sample))\n",
        "\n",
        "    angle = (angle - 0.5) * angleconstraint\n",
        "    nsample = sample.copy()\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = rotate(sample[ii], angle[ii])\n",
        "    return np.squeeze(nsample)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_X[20]\n",
        "angleconstraint = 70\n",
        "\n",
        "fig, axs = plt.subplots(1, 5, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(sample, cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[1].set_title(\"Aug. Sample 1\")\n",
        "\n",
        "axs[2].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[2].set_title(\"Aug. Sample 2\")\n",
        "\n",
        "axs[3].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[3].set_title(\"Aug. Sample 3\")\n",
        "\n",
        "axs[4].imshow(augRotate(sample, angleconstraint), cmap=\"gray\")\n",
        "axs[4].set_title(\"Aug. Sample 4\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nOKFnbWuT0_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U1kcsU6PHFy"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "# plot the variation of accuracy\n",
        "ax.plot(angleconstraints, accuracies)\n",
        "ax.set_xlabel(\"angle\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(angleconstraints[maxind], accuracies[maxind], c=\"red\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx52LXVmPJdc"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "angleconstraint = 60\n",
        "naugmentations = 5\n",
        "\n",
        "# augment\n",
        "augdata = train_X  # we include the original images also in the augmented dataset\n",
        "auglabel = train_y\n",
        "for ii in range(naugmentations):\n",
        "    augdata = np.concatenate(\n",
        "        (augdata, augRotate(train_X, angleconstraint))\n",
        "    )  # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate(\n",
        "        (auglabel, train_y)\n",
        "    )  # the labels don't change when we augment\n",
        "\n",
        "# check the test accuracy\n",
        "testpred = NN(augdata, auglabel, test_X)\n",
        "print(\"Accuracy after rotation augmentation:\", Accuracy(test_y, testpred)*100, \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "angleconstraints = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]  # the values we want to test\n",
        "accuracies = np.zeros(\n",
        "    len(angleconstraints), dtype=float\n",
        ")  # we will save the values here\n",
        "\n",
        "for ii in range(len(angleconstraints)):\n",
        "    # create the augmented dataset\n",
        "    augdata = train_X  # we include the original images also in the augmented dataset\n",
        "    auglabel = train_y\n",
        "    for jj in range(naugmentations):\n",
        "        augdata = np.concatenate(\n",
        "            (augdata, augRotate(train_X, angleconstraints[ii]))\n",
        "        )  # concatenate the augmented data to the set\n",
        "        auglabel = np.concatenate(\n",
        "            (auglabel, train_y)\n",
        "        )  # the labels don't change when we augment\n",
        "\n",
        "    # check the test accuracy\n",
        "    testpred = NN(augdata, auglabel, test_X)\n",
        "    accuracies[ii] = Accuracy(test_y, testpred)\n",
        "    print(\n",
        "        \"Accuracy after rotation augmentation constrained by\",\n",
        "        angleconstraints[ii],\n",
        "        \"degrees is\",\n",
        "        accuracies[ii]*100,\n",
        "        \"%\",\n",
        "        flush=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "CRZmuOVCXUw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])\n",
        "# plot the variation of accuracy\n",
        "ax.plot(angleconstraints, accuracies)\n",
        "ax.set_xlabel(\"angle\")\n",
        "ax.set_ylabel(\"accuracy\")\n",
        "\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(angleconstraints[maxind], accuracies[maxind], c=\"red\")"
      ],
      "metadata": {
        "id": "gs7aI0V2XX7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation 2: Shear"
      ],
      "metadata": {
        "id": "5Ry968XFXb9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shear(sample, amount):\n",
        "\n",
        "    tform = AffineTransform(shear=amount)\n",
        "    img = warp(sample, tform)\n",
        "\n",
        "    col = img.sum(0).nonzero()[0]\n",
        "    row = img.sum(1).nonzero()[0]\n",
        "    if len(col) > 0 and len(row) > 0:\n",
        "        xshift = int(sample.shape[0] / 2 - (row[0] + row[-1]) / 2)\n",
        "        yshift = int(sample.shape[1] / 2 - (col[0] + col[-1]) / 2)\n",
        "        img = np.roll(img, (xshift, yshift), (0, 1))\n",
        "    return img"
      ],
      "metadata": {
        "id": "64ZCETolXgWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = train_X[2]\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
        "\n",
        "axs[0].imshow(sample, cmap=\"gray\")\n",
        "axs[0].set_title(\"Original Image\")\n",
        "\n",
        "axs[1].imshow(shear(sample, 0.2), cmap=\"gray\")\n",
        "axs[1].set_title(\"Amount = 0.2\")\n",
        "\n",
        "axs[2].imshow(shear(sample, 0.4), cmap=\"gray\")\n",
        "axs[2].set_title(\"Amount = 0.4\")\n",
        "\n",
        "axs[3].imshow(shear(sample, 0.6), cmap=\"gray\")\n",
        "axs[3].set_title(\"Amount = 0.6\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u78UOuReXnuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augShear(sample, shearconstraint):\n",
        "    if shearconstraint == 0:\n",
        "        return sample\n",
        "    if len(sample.shape) == 2:\n",
        "\n",
        "        sample = np.expand_dims(sample, 0)\n",
        "    amt = rng.random(len(sample))\n",
        "    amt = (amt - 0.5) * shearconstraint\n",
        "    nsample = sample.copy()\n",
        "    for ii in range(len(sample)):\n",
        "        nsample[ii] = shear(sample[ii], amt[ii])\n",
        "    return np.squeeze(nsample)"
      ],
      "metadata": {
        "id": "n5Bn5vybXp52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MelaPoREXy5I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEcYif7111g3Qg1Wec3Iha",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}